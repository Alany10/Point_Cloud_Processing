{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51855908",
   "metadata": {},
   "source": [
    "# Point Cloud Processing\n",
    "\n",
    "Alan Youssef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa7527",
   "metadata": {},
   "source": [
    "## Task 1: Finding the Ground Level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf4bfd",
   "metadata": {},
   "source": [
    "In this task, our goal is to identify the ground level in LiDAR point cloud data. LiDAR captures 3D points of the environment, including the ground, buildings, trees, and other objects. To analyze or segment these points properly, we first need to separate the ground points from everything else.\n",
    "\n",
    "We solve this by analyzing the height (Z) values of all points. A histogram of Z-values helps us see where most points are located vertically. The tallest peak in the histogram usually corresponds to the ground because most of the scene is typically ground-level points. \n",
    "\n",
    "Using this method, we estimate the ground level and then remove all points below it. This allows us to focus only on objects above the ground for further analysis, like clustering or object detection. \n",
    "\n",
    "We also visualize the histogram and the 3D point cloud above the ground to verify our results. This task is important because correctly identifying the ground level ensures that subsequent analyses, such as clustering with DBSCAN, are more accurate and meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#%% utility functions\n",
    "def show_cloud(points_plt):\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.scatter(points_plt[:,0], points_plt[:,1], points_plt[:,2], s=0.01)\n",
    "    plt.show()\n",
    "\n",
    "def show_scatter(x,y):\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "def get_ground_level(pcd, dataset_name=\"dataset\"):\n",
    "    z_values = pcd[:, 2]  # ta höjddata\n",
    "\n",
    "    # skapa histogram\n",
    "    counts, bins = np.histogram(z_values, bins=100)\n",
    "    max_bin_index = np.argmax(counts)\n",
    "    ground_level = (bins[max_bin_index] + bins[max_bin_index + 1]) / 2\n",
    "\n",
    "    # plotta och spara histogram\n",
    "    plt.figure()\n",
    "    plt.hist(z_values, bins=100)\n",
    "    plt.axvline(ground_level, color='red', linestyle='--',\n",
    "                label=f'Ground level: {ground_level:.2f}')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Höjd (Z)\")\n",
    "    plt.ylabel(\"Antal punkter\")\n",
    "    plt.title(f\"Histogram av höjdfördelning ({dataset_name})\")\n",
    "    plt.savefig(f\"images/histogram_{dataset_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return ground_level\n",
    "\n",
    "#%% Lista med dataset-filer\n",
    "datasets = [\"dataset1.npy\", \"dataset2.npy\"]\n",
    "\n",
    "#%% Kör analysen för varje dataset\n",
    "for filename in datasets:\n",
    "    print(f\"Processing {filename}...\")\n",
    "    pcd = np.load(filename)\n",
    "    \n",
    "    # beräkna marknivå\n",
    "    est_ground_level = get_ground_level(pcd, dataset_name=filename.split('.')[0])\n",
    "    print(f\"{filename}: Beräknad marknivå = {est_ground_level:.2f}\")\n",
    "    \n",
    "    # ta bort marknivå för visualisering\n",
    "    pcd_above_ground = pcd[pcd[:,2] > est_ground_level]\n",
    "    \n",
    "    print(f\"{filename}: Antal punkter ovanför marknivå = {pcd_above_ground.shape[0]}\")\n",
    "    \n",
    "    # visa punktskyen\n",
    "    %matplotlib qt\n",
    "    show_cloud(pcd_above_ground)\n",
    "\n",
    "    # Exempel på DBSCAN-klustring för det första datasetet\n",
    "    if filename == \"dataset1.npy\":\n",
    "        unoptimal_eps = 10\n",
    "        clustering = DBSCAN(eps=unoptimal_eps, min_samples=5).fit(pcd_above_ground)\n",
    "        \n",
    "        clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "        colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, clusters)]\n",
    "        \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.scatter(pcd_above_ground[:,0], \n",
    "                    pcd_above_ground[:,1],\n",
    "                    c=clustering.labels_,\n",
    "                    cmap=matplotlib.colors.ListedColormap(colors),\n",
    "                    s=2)\n",
    "        plt.title('DBSCAN: %d clusters' % clusters, fontsize=20)\n",
    "        plt.xlabel('x axis', fontsize=14)\n",
    "        plt.ylabel('y axis', fontsize=14)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27534c59",
   "metadata": {},
   "source": [
    "## Task 2 – Optimizing DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d3227",
   "metadata": {},
   "source": [
    "In Task 2, we focused on finding an optimal parameter for DBSCAN called `eps`. This parameter determines how close points need to be to each other to belong to the same cluster. If `eps` is too small, many points will be considered \"noise\" and not belong to any cluster. If `eps` is too large, separate objects may be merged into a single cluster.\n",
    "\n",
    "To find a suitable `eps`, we used an **elbow plot** based on the distance to each point's 5th nearest neighbor. By sorting these distances and looking for the \"elbow\" in the graph, we can heuristically choose a value that balances between too many small clusters and too few large clusters.\n",
    "\n",
    "After determining an approximate optimal `eps`, we ran DBSCAN again and visualized the clusters. This step ensures that the parameter works in practice—meaning the clusters represent real objects in the LiDAR data, such as buildings, trees, or cars.\n",
    "\n",
    "The outcomes of Task 2 are:  \n",
    "1. An elbow plot showing how we selected `eps`.  \n",
    "2. A final cluster plot showing meaningful clusters in the data.\n",
    "\n",
    "These visualizations were saved in the `images` folder to include them in the project Readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fdfbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset1.npy for Task 2...\n",
      "dataset1.npy: Optimal eps = 0.39\n",
      "Processing dataset2.npy for Task 2...\n",
      "dataset2.npy: Optimal eps = 0.36\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_optimal_eps(pcd_above_ground, dataset_name=\"dataset\"):\n",
    "    # Skapa NearestNeighbors-objekt\n",
    "    neigh = NearestNeighbors(n_neighbors=5)\n",
    "    nbrs = neigh.fit(pcd_above_ground[:, :2])  # endast XY-plan\n",
    "    distances, indices = nbrs.kneighbors(pcd_above_ground[:, :2])\n",
    "    \n",
    "    # Ta avstånd till 5:e närmaste granne\n",
    "    k_distances = np.sort(distances[:, 4])\n",
    "    \n",
    "    # Plotta och spara elbow\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_distances)\n",
    "    plt.xlabel(\"Points sorted by distance\")\n",
    "    plt.ylabel(\"5th Nearest Neighbor Distance\")\n",
    "    plt.title(f\"Elbow plot for {dataset_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"images/elbow_{dataset_name}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Heuristiskt sätt att hitta \"elbow\": vi tar ett ungefärligt värde\n",
    "    optimal_eps = np.percentile(k_distances, 95)  # kan justeras visuellt\n",
    "    return optimal_eps\n",
    "\n",
    "#%%\n",
    "for filename in datasets:\n",
    "    print(f\"Processing {filename} for Task 2...\")\n",
    "    pcd = np.load(filename)\n",
    "    est_ground_level = get_ground_level(pcd, dataset_name=filename.split('.')[0])\n",
    "    pcd_above_ground = pcd[pcd[:,2] > est_ground_level]\n",
    "\n",
    "    # Hitta optimal eps\n",
    "    optimal_eps = find_optimal_eps(pcd_above_ground, dataset_name=filename.split('.')[0])\n",
    "    print(f\"{filename}: Optimal eps = {optimal_eps:.2f}\")\n",
    "\n",
    "    # Kör DBSCAN med optimal eps\n",
    "    clustering = DBSCAN(eps=optimal_eps, min_samples=5).fit(pcd_above_ground)\n",
    "    clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, clusters)]\n",
    "    \n",
    "    # Plotta och spara klusterplot\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(pcd_above_ground[:,0], \n",
    "                pcd_above_ground[:,1],\n",
    "                c=clustering.labels_,\n",
    "                cmap=matplotlib.colors.ListedColormap(colors),\n",
    "                s=2)\n",
    "    plt.title(f'DBSCAN: {clusters} clusters ({filename})', fontsize=20)\n",
    "    plt.xlabel('x axis', fontsize=14)\n",
    "    plt.ylabel('y axis', fontsize=14)\n",
    "    plt.savefig(f\"images/clusters_{filename.split('.')[0]}.png\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca483ed",
   "metadata": {},
   "source": [
    "![Histogram dataset1](images/histogram_dataset1.png)\n",
    "![Histogram dataset2](images/histogram_dataset2.png)\n",
    "![Elbow plot dataset1](images/elbow_dataset1.png)\n",
    "![Elbow plot dataset2](images/elbow_dataset2.png)\n",
    "![Clusters dataset1](images/clusters_dataset1.png)\n",
    "![Clusters dataset2](images/clusters_dataset2.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
